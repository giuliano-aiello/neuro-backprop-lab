\begin{subsection}{Loader Dataset}
    \label{subsubsec:loader-dataset}
    \par This class, \texttt{loader-dataset.py}, is responsible for the methodology employed for data retrieval. It is the module that takes the most importance of the \texttt{utils} package, so it was worth describing it.
    \par Data is normalized from the integer range $[0, 255]$ to the real-valued range $[-1, 1]$.
    \input{chapter/module-overview/utils/loader_dataset/pseudocode/loader_dataset}
    \par The method used to get the data is holdout, the learning data is completely separated from the testing data with the \texttt{learn\_mode} parameter.
    \par The learning set is, in turn, split into the train set for the training phase and in the eval set for the evaluation phase. Finally, the train set undergoes a data shuffle, this should make the train phase more robust. The eval set comes in handy to avoid overfitting.\\
    \par It is also important to note that the~\glsxtrshort{mnist}~allocates $60,000$ samples for training and $10,000$ for testing.
\end{subsection}